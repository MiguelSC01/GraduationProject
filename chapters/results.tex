\chapter{Results}\label{chap:results}


\section{Introduction}  

In this chapter, we present the main results of this thesis. We will prove a theorem similar to parts (b) and (c) of Theorem \ref{thm:ermodel} using standard probabilistic arguments. 

\begin{theorem}\label{thm:main}
    Let $\mathcal{S} \sim \mathcal{S}(M, p)$, where $p = p(M)$ is a monotone decreasing function of $M$ and $\frac{1}{M} \in o(p(M))$. Then, 
\begin{enumerate}[label=(\alph*)]
    \item If $\lim_{M \to \infty} p(M) = 0$, then for every $K \in \N$,   
    \[\lim_{M \to \infty} \Pr[e(\mathcal{S}) > K] = \lim_{M \to \infty} \Pr[g(\mathcal{S}) > K] = \lim_{M \to \infty} \Pr[F(\mathcal{S}) > K] = 1.\]
    \item If $\lim_{M \to \infty} p(M) > 0$, then $e(\mathcal{S}), \; g(\mathcal{S})$ and $F(\mathcal{S})$ are bounded in probability, i.e., for every $\varepsilon > 0$, there exists $K_\varepsilon$ such that 
    \[ \Pr[e(\mathcal{S}) < K_\varepsilon] > 1 - \varepsilon, \quad  \Pr[g(\mathcal{S}) < K_\varepsilon] > 1- \varepsilon \quad \text{and} \quad \Pr[F(\mathcal{S}) < K_\varepsilon] > 1 - \varepsilon.\]
\end{enumerate}
Furthermore, there exist explicit functions $\varphi, \psi$ such that 
\[\lim_{p \to 0} \Pr\left[e(\mathcal{S}) < \varphi\left(\frac{1}{p}\right)\right] = \lim_{p \to 0} \Pr\left[g(\mathcal{S}) < \psi\left(\frac{1}{p}\right)\right]  = \lim_{p \to 0} \Pr\left[F(\mathcal{S}) < \psi\left(\frac{1}{p}\right)\right] = 1.\]
\end{theorem}
Note that part (a) is \textit{stronger} than part (b) of Theorem \ref{thm:ermodel}. However, part (b) of this theorem does not imply part (c) of Theorem \ref{thm:ermodel}. The proof of part (b) of this theorem is based on Lemma \ref{lem:sumset}, which is a result on sums of random subsets of cyclic groups.  

\section{Lower Bound}\label{sec:results:lowerbound}

We first prove part (a) of Theorem \ref{thm:main}. 

\textbf{Proof of Theorem \ref{thm:main} part (a)}

We will show that, for each fixed number of generators $a$, there is a high probability that at least $a$ minimal generators are chosen as $p \to 0$.

\textbf{Proof. }
Fix $a \in \NN$ such that $a > 11$ and let $T = \{1, \ldots, \lfloor\frac{a}{p}\rfloor\}$. Since   $\frac{1}{M} \in o(p)$, we have that $\lfloor\frac{a}{p}\rfloor \leq M$ for large enough $M$. Consider the following events:
\begin{itemize}
    \item $E_1$: No generator selected is less than $\frac{1}{ap}$.  \par
    Let $X_1$ be the number of generators selected from $\{1,\ldots,\lfloor\frac{1}{ap}\rfloor\}$. Then 
    \begin{equation}\label{eq:lowerbound:e1}
    \Pr[\lnot E_1] = \Pr[X_1 > 0] \leq \EE[X_1] \leq p \cdot \frac{1}{ap} = \frac{1}{a}.
    \end{equation}

    \item $E_2:$ At most $\frac{3a}{2}$ generators are selected from $T$.\par 
    Let $X_2$ be the number of generators selected in $T$, then $X_2 \sim \mathrm{Bin}(\frac{a}{p}, p)$ and we can use the bound in Proposition \ref{ap:prop:rightbinomtail} with $r = \frac{3a}{2}$ to get that

    \[\Pr[\lnot E_2] = \Pr\left[X_2 > \frac{3a}{2}\right] \leq  \frac{\frac{3a}{2}(1 - p)}{(\frac{3a}{2} - a)^2} = \frac{\frac{3a}{2}(1 - p)}{(\frac{a}{2})^2}\leq \frac{6}{a}.\]

    Also, by the union bound and (\ref{eq:lowerbound:e1}),
    \begin{equation}\label{eq:lowerbound:e1ande2}
     \Pr[E_1\land E_2] \geq 1 - \frac{1}{a} - \frac{6}{a} = 1 - \frac{7}{a}.
    \end{equation}

    \item $E_3:$ At least $\frac{a}{2}$ generators are selected from $T$. \par 
    Similarly, we can use the bound for the left tail (Proposition \ref{ap:prop:leftbinomtail}) with $r = \frac{a}{2}$ to get that
    \begin{equation}\label{eq:lowerbound:e3}
        \Pr[ \lnot E_3] = \Pr\left[X_2 < \frac{a}{2}\right] \leq  \frac{(n - \frac{a}{2})p}{(np - \frac{a}{2})^2} = \frac{a - (\frac{a}{2})p}{(\frac{a}{2})^2} \leq \frac{4}{a}.
    \end{equation}
    \item $E_4:$ The generators selected from $T$ are all minimal.\par 
    Let $A_T = \{Y_{(1)}, Y_{(2)}, \ldots, Y_{(k)}\}$ be the generators selected in $T$ in order. Assume $E_1$ and $E_2$. We have that $E_1$ implies $Y_{(1)} \geq \frac{1}{ap}$ and $E_2$ implies $k \leq \frac{3a}{2}$. \par
    First we bound the probability that $b \in T$ is selected as a generator. Using conditional probability, we have that 
    \begin{align}
        \Pr[b \in \mathcal{A}_T|E_1 \land E_2] &= \frac{\Pr[(b \in \mathcal{A}_T)\land E_1 \land E_2]}{\Pr[E_1 \land E_2]} \\
        &\leq\frac{\Pr[b \in \mathcal{A}_T]}{\Pr[E_1 \land E_2]} = \frac{p}{1 - \frac{7}{a}}. \label{eq:lowerbound:inequality}
    \end{align}
    Now, if no multiple of $Y_{(1)}$ is selected in $T$, then $Y_{(2)}$ is minimal. Thus, $Y_{(2)}$ is minimal if $\langle y_1 \rangle \cap  \mathcal{A}_T = \{y_1\}$. Also, note that, since the generators are chosen independently,
    \[P[b \in \mathcal{A}_T] = P[b \in \mathcal{A}_T|Y_{(1)} = y_1] \quad \text{if} \quad  b > y_1.\]
    Since $y_1 \geq \frac{1}{ap}$, we have that \[|\langle y_1 \rangle \cap  \mathcal{A}_T| \leq |\langle y_1 \rangle \cap T| \leq a^2.\] Then, using the union bound and (\ref{eq:lowerbound:inequality}),
    \begin{align*}
        \Pr[Y_{(2)} \text{ is not minimal}|E_1\land E_2 \land Y_{(1)} = y_1]&\leq \sum_{b \in\langle y_1\rangle \cap T}\Pr[b \in \mathcal{A}_T|E_1 \land E_2 \land Y_{(1)} = y_1]\\ 
        &\leq \sum_{b \in\langle y_1\rangle \cap T} \frac{p}{1 - \frac{7}{a}} \leq \frac{pa^2}{1 - \frac{7}{a}}.
    \end{align*}
        
    If this bound is independent of $y_1$, we get that 
    \begin{equation}\label{eq:lowerbound:y2notminimal}
        \Pr[Y_{(2)} \text{ is not minimal}|E_1\land E_2] \leq \frac{pa^2}{1 - \frac{7}{a}}.
    \end{equation}
    Similarly, for $2 \leq t \leq k$ and fixed $Y_{(1)} = y_1, \ldots, Y_{(t - 1)} = y_{t - 1}$, $Y_{(t)}$ is minimal if $\langle y_1, \ldots, y_{t - 1}\rangle \cap \mathcal{A}_T = \{y_1, \ldots, y_{t - 1}\}$. To bound $|\langle y_1, \ldots, y_{t - 1}\rangle \cap \mathcal{A}_T|$, there are at most $a^2$ choices for each multiple of $y_i$, so there are at most $a^{2(t - 1)}$ such linear combinations and
    \[|\langle y_1, \ldots, y_{t - 1} \rangle \cap  \mathcal{A}_T| \leq |\langle y_1, \ldots, y_{t - 1} \rangle \cap T| \leq a^{2(t - 1)}.\]
    Also, 
    \[P[b \in \mathcal{A}_T] = P[b \in \mathcal{A}_T|Y_{(1)} = y_1\land \cdots \land Y_{(t - 1)} = y_{t - 1}] \quad \text{if} \quad  b > y_{t - 1} > \ldots > y_1,\]
    and so
    \[
        \Pr[b \in \mathcal{A}_T|E_1 \land E_2 \land Y_{(1)} = y_1 \land \cdots \land Y_{(t - 1)} = y_{t - 1}] \leq \frac{p}{1 - \frac{7}{a}}.
    \]
    Then, as in (\ref{eq:lowerbound:y2notminimal}), 
    \[\Pr[Y_{(t)} \text{ is not minimal}|E_1\land E_2] \leq \frac{pa^{2t}}{1 - \frac{7}{a}} .\]
    Therefore, we can use the union bound and $k \leq \frac{3a}{2}$ to conclude that
    \[\Pr[E_4|E_1 \land E_2] \geq 1 - \frac{p}{1 - \frac{7}{a}}\sum_{t = 1}^{\frac{3a}{2} - 1}a^{2(t - 1)} = 1 - o(1),\]
    since $a$ is constant and $p \to 0$ as $M  \to \infty$.
    Thus,  
    \begin{equation}\label{eq:lowerbound:e4}
        \Pr[E_4] = \Pr[E_4| E_1 \land E_2]\Pr[E_1\land E_2] \geq 1 - \frac{7}{a} - o(1).
    \end{equation}
\end{itemize}


Finally, note that by the union bound, (\ref{eq:lowerbound:e3}) and (\ref{eq:lowerbound:e4}),
\[\Pr[E_4 \land E_3] \geq 1 - \frac{11}{a} - o(1).\] 
This means that for $\varepsilon > 0$ and sufficiently large $a$ and $M$, the probability that at least $\frac{a}{2}$ minimal generators are selected is greater than $1 - \varepsilon$. Threfore, for every $K \in \NN$, 
\[\lim_{M \to \infty} \Pr[e(\mathcal{S}) > K] = 1.\]
Now, using Corollary \ref{cor:smgps:embedding_dim} and Proposition \ref{prop:smgps:frobgenus}, we have that
\[e(S) \leq m(S) \leq g(S) + 1 \leq F(S) + 1.\]
We conclude that, for every $K \in \NN$,
\[\lim_{M \to \infty} \Pr[g(\mathcal{S}) > K] = \lim_{M \to \infty} \Pr[F(\mathcal{S}) > K] = 1.\qed\]

\section{Upper bound}\label{sec:results:upperbound}
Before proving part (b) of theorem \ref{thm:main}, we will prove a lemma that shows that a cyclic group of prime order is covered by the sums of a random subset of logarithmic size.  
\begin{lemma}\label{lem:sumset}
    Let $q$ be a prime number and $\mathcal{A}$ be a random subset of $\mathbb{Z}_q$ of size $4\lfloor3\log_2 q\rfloor$. As $q$ tends to infinity, $2\lfloor3\log_2 q\rfloor S$ covers $\mathbb{Z}_q$ almost always. 
\end{lemma}

\textbf{Proof. } Let $s \in \mathbb{N}$ such that $s\leq q$. Let $\mathcal{A}$ be a uniformly random subset of $\mathbb{Z}_q$ of size $s$, that is, 
\[\Pr(\mathcal{A}) = \frac{1}{\binom{q}{s}}.\]
For a given $z \in \mathbb{Z}_q$ and $k \in \mathbb{N}$ for which $k \leq s/2$, let 
\[N_z^k := \left\{K \subseteq \mathbb{Z}_q: |K| = k, \sum_{t \in K} t = z\right\}.\]
Note that $|N_z^k| = \frac{1}{q}{\binom{q}{k}}$, since $K \in N_0^k$ if and only if $K + k^{-1}z \in N_z^k$ for every $z \in \mathbb{Z}_q$.\par
For $K \in N_z^k$, let $A_K$ be the event that $K \subset\mathcal{A}$. Let $X_K$ be the indicator variable of $A_K$.
We define the random variable 
\[X_z = \sum_{K \in N_z^k} X_K.\]
Note that $X_z$ counts the number of sets of size $k$ which add up to $z$. We now find $\EE[X_z]$. Since the sum of every subset $K \subset S$ is in $\mathbb{Z}_q$,
\[\sum_{z \in Z_q} X_z = {\binom{s}{k}},\]
and so
\[\binom{s}{k} = E\left[\sum_{z \in Z_q} X_z\right] =  \sum_{z \in Z_q} E[X_z].\]\par
As in the argument for finding $|N_z^k|$, for every $z \in \mathbb{Z}_q$, 
\[\EE[X_0] = \sum_{K \in N_0^k}\EE[X_K] = \sum_{K \in N_0^k} \EE[X_{K + k^{-1}z}] = \sum_{K \in N_z^k} \EE[X_K] = \EE[X_z].\]
Therefore, we have that
\begin{equation}\label{eq:upperbound:expected}
E[X_z] = \frac{1}{q} {\binom{s}{k}}.
\end{equation}
Now, for $K, L \in N_z^k$, let $j \in \mathbb{N}$ such that $j \leq k$ and define
\[\Delta_j := \sum_{|K \cap L| = j} \Pr[A_K \land A_L].\]
\par 
If $|K \cap L| = j$,
\[\Pr[A_K \land A_L] = \frac{\binom{q - 2k + j}{s - 2k + j}}{\binom{q}{s}}.\]
\par
We can bound the number of events for which $|K \cap L| = j$. First we choose $K$ as any set in $N_z^k$ and then we choose the remaining $k- j$ elements as any subset of $\mathbb{Z}_q \setminus K$ with size $k - j$. Thus, \textcolor{blue}{explain a little bit better}
\[\Delta_j \leq \frac{\binom{p}{k} \binom{q - k}{k - j}\binom{q - 2k + j}{s - 2k + j}}{q\binom{q}{s}}.\]
\par This implies that, using \ref{eq:upperbound:expected},
\begin{align*}
    \frac{\Delta_j}{\EE[X_z]^2} &\leq \frac{\binom{q}{k} \binom{q - k}{k - j}\binom{q - 2k + j}{s - 2k + j}}{\frac{1}{q} \binom{s}{k}\frac{1}{q} \binom{s}{k}q\binom{q}{s}} \\
    &= \frac{\frac{q!}{(q - k)!k!}\frac{(p - k)!}{(k - j)!(q - 2k + k)!}\frac{(q - 2k + j)!}{(s - 2k + j)!(q - s)!}}{\frac{1}{q}\binom{s}{k}\frac{s!}{(s - k)!k!}\frac{q!}{(q - s)!s!}} \\
    &= \frac{q\binom{s - k}{k - j}}{\binom{s}{k}}.
\end{align*}
Let $s = 4\lfloor 3 \log_2 q \rfloor$ and $k = 2\lfloor 3 \log_2 q \rfloor$. Using that $\binom{s - k}{k - j}$ is maximized at $k - j = \lfloor (s - k) / 2\rfloor$,
\begin{align*}
\frac{\Delta_j}{\EE[X_z]^2} \leq \frac{q \binom{2\lfloor 3 \log_2 q\rfloor}{\lfloor 3 \log_2 q \rfloor}}{\binom{4\lfloor 3\log_2 q \rfloor}{2\lfloor 3\log_2 q \rfloor}} \leq \frac{q}{\binom{2\lfloor 3 \log_2 q \rfloor }{ \lfloor 3 \log_2 q \rfloor}} \leq \frac{q}{2^{\lfloor 3 \log_2 q \rfloor}} \sim \frac{1}{q^2},
\end{align*}
since \(\binom{2\lfloor \log_2 q \rfloor}{\lfloor 3 \log_2 q \rfloor}^2 \leq \binom{4\lfloor 3 \log_2 q \rfloor }{2\lfloor 3 \log_2 q \rfloor}\) (Proposition \ref{ap:prop:binom}).   \par
Hence, by (\ref{eq:probmet:deltainequality}) and Theorem \ref{thm:probmet:secondmoment:1},
\begin{align*}
\Pr[X_z = 0] \leq \frac{\EE[X_z] + \Delta}{\EE[X_z]^2} &= \frac{1}{E[X_z]} + \sum_{j = 0}^k \frac{\Delta_j}{\EE[X_z]^2} \\
&\leq \frac{1}{E[X_z]} + \frac{(k + 1)}{q^2} = \frac{1}{E[X_z]} + \frac{2\lfloor 3 \log_2 q\rfloor + 1}{q^2}.
\end{align*}
Therefore, by the union bound and since $q \to \infty$ as $p \to 0$,
\[\Pr\left[\bigvee_{z \in \mathbb{Z}_q} X_z = 0\right] \leq \frac{q}{E[X_z]} + \frac{q(2\lfloor 3 \log_2 q\rfloor + 1)}{q^2} = o(1).\]
We conclude that $X_z > 0$ for every $z \in \mathbb{Z}_q$ almost always. Thus, for every $z \in \mathbb{Z}_q$, there exists $K \in N_z^k$ such that $K \subset \mathcal{A}$ almost always. This means that $2\lfloor 3 \log_2 q\rfloor S$ covers $\mathbb{Z}_q$ almost always. \qed

\subsection{Proof of the upper bound} 
\begin{lemma}\label{lem:upperbound}
    Let $g(x)$ be a function for which $x(\log x)^2 \in o(g(x))$ .Then
    \[\lim_{p \to 0}\Pr\left[F(S) \leq g\left(\frac{1}{p}\right)\right] = 1.\] 
\end{lemma}

\par The proof of this theorem consists of several parts. The strategy is to prove that the Ápery set of a subsemigroup of $S$ is completed before step $g\left(\frac{1}{p}\right)$ with high probability, since $F(S)$ is less than the maximum element of this Ápery set. The proof has the following structure: 
\begin{enumerate}
\item First, we will find a step for which a prime $q$ is chosen with high probability (E1). 
\item Then, in the spirit of Lemma \ref{lem:sumset} we will find a step such that $s$ elements which are different modulo $q$ are chosen with high probability (E2). 
\item Finally, we will apply Lemma \ref{lem:sumset} to $\mathrm{Ap}(\mathcal{S}, q)$.
\end{enumerate}
\textbf{Proof. }
\subsubsection*{Part 1} 
Let \(h(x)\) be a function such that \(h(x) \in o(x (\log x)^2)\) and \(x\log x \in o(h(x))\). Let $t(x) = 20x \log x$. Consider the event
$E_1$ that there exists a prime $q \in S$, such that 
\[t\left(\frac{1}{p}\right) \leq q \leq h\left(\frac{1}{p}\right).\]
\par 
Let $q_n$ be the $n$-th prime number and let $k_x$ be the number of primes between $20x\log x$ and $h(x)$. For $n \geq 6$, by the \textcolor{blue}{Prime Number Theorem}, 
\[n(\log n + \log \log n - 1) < q_n < n(\log n + \log\log n) = o(h(n)).\]

\par Thus, $n = o(k_n)$ (\textcolor{blue}{I can prove this if it is not clear}) and, for every $c > 0$,  
\[\lim_{p \to 0}\Pr[\lnot E_1] \geq \lim_{p \to 0} (1 - p)^{k_{\frac{1}{p}}} \geq \lim_{p \to 0} (1 - p)^{\frac{c}{p}} = e^{-c}.\]
Therefore, 
\[\lim_{p \to 0}\Pr[E_1] = 1.\]
\subsubsection*{Part 2}

Now, assume $E_1$. Then $S$ contains a prime number $q$ for which 
\[t\left(\frac{1}{p}\right) \leq q \leq h\left(\frac{1}{p}\right).\]
\par Let $s = 4\lfloor3\log_2 q \rfloor$, as in the \textcolor{blue}{Lemma}. 
\par Let $A := \{q + 1, q + 2, \ldots,  2q\}$. Consider the event \textbf{E2} that at least $s$ generators are selected in $A$. Let $X_1$ be the number of generators selected in $A$, then $X_1$ is a binomial random variable with parameters $n = q$ and $p$. Then, in a similar way to $E2$ in \textcolor{blue}{Theorem 1}, we use the \textcolor{blue}{Binomial Distribution Tail Bound} to show that, assuming that $p$ is small enough so that $qp > s$ for all possible $q$,
\begin{align*}
    \Pr[ \overline{E_2}  | E_1] = \Pr\left[X_1 < s\right] \leq \Pr\left[X_2 < s\right] \leq \frac{(n - s)p}{(np - s)^2} = \frac{(q - s)p}{(qp - s)^2}.
\end{align*}
\par Thus, bounding by the worst case asymptotically, (\textcolor{blue}{needs to be explained better})
\[\lim_{p \to 0} P[\overline{E_2} | E_1] =  \lim_{p \to 0}\frac{\left(h\left(\frac{1}{p}\right) - 4\left\lfloor3\log_2 h\left(\frac{1}{p}\right) \right\rfloor\right)p}{\left(20 \log \frac{1}{p} - 4\lfloor3\log_2 t\left(\frac{1}{p}\right) \rfloor\right)^2} = 0.\]
\par We conclude that
\[\lim_{p \to 0} \Pr[E_2 | E_1] = 1,\]
and so
\[\lim_{p \to 0} \Pr[E_1 \land E_2] = \lim_{p \to 0} \Pr[E_2  | E_1]\Pr[E_1] = 1.\]


\subsubsection*{Part 3}

\par Finally, assume $E_1$ and $E_2$. Let $B = \{Y_{1}, \ldots, Y_{s}\}$ be a randomly selected subset of size $s$ of the generators selected in $E_2$.  Since the generators are chosen randomly and $|A| = q$, we can apply the \textcolor{blue}{Lemma} to the Ápery set of the subsemigroup generated by $B$, denoted by $G(B)$, and conclude that the Ápery set of $G(B)$ will be completed before step $h\left(\frac{1}{p}\right)2\left\lfloor 3\log_2 h\left(\frac{1}{p}\right)\right\rfloor$ with high probability as $p \to 0$. 
\par Thus, if $g(x)$ be a function for which $x(\log x)^2 \in o(g(x))$ (\textcolor{blue}{Probably needs to be explained better}),
\[\lim_{p \to  0} \Pr\left[F(G(B)) \leq g\left(\frac{1}{p}\right)\right] = 1.\]
Since $F(S) \leq F(G(B))$, we conclude that
\[\lim_{p \to 0}\Pr\left[F(S) \leq g\left(\frac{1}{p}\right)\right] = 1. \qed \] 


\section{Conclusions and Further work}
