\chapter{Results}\label{chap:results}

\section{Introduction}

In this chapter, we present the main results of this Thesis. We start by proving a Theorem found in \cite{de2018random} without the use of the simplicial complex. 

\section{Lower Bound}\label{sec:results:lowerbound}

We prove a Theorem found in \cite{de2018random} without the use of the simplicial complex. 

\begin{theorem}
    Let $S \sim S(M, p)$, where $p = p(M)$ is a monotone decreasing function of M. If $\frac{1}{M} \ll p \ll 1$, then $S$ is cofinite, i.e., the set of gaps is finite, a.a.s and 
\[\lim_{M \to \infty} \EE[e(S)] = \lim_{M \to \infty} \EE[g(S)] = \lim_{M \to \infty} \EE[F(S)] = \infty.\]
\end{theorem}

\textbf{Proof. } Let $X := \min(S \setminus \{0\})$ be a random variable. Then, for $0 < n \leq M$,
\begin{align*}
    \Pr[X = n] = p(1 - p)^{n - 1}, 
\end{align*}
and so 
\begin{align*}
    \EE[X] &= \sum_{n = 0}^{\infty} n\Pr[X = n] =
    \sum_{n = 0}^{M} np(1 - p)^{n - 1} = p\frac{d}{dp}\left[-\sum_{n = 0}^{M}(1 - p)^n\right]\\
    &=p\frac{d}{dp} \frac{(1 - p)^{M + 1} - 1}{p} = p\frac{1 - (1 - p)^{M + 1} - (M  + 1)(1 - p)^Mp}{p^2} \\
    &= \frac{1 - (1 - p)^{M} - M(1 - p)^Mp}{p} \geq \frac{1 - e^{-Mp} - Mpe^{-Mp}}{p}. \\
\end{align*}
Thus, since $\lim_{M \to \infty} Mp = \infty$, then $\lim_{M \to \infty }Mpe^{-Mp} = \lim_{M \to \infty} e^{-Mp} = 0$, which implies that
\[\lim _{M \to \infty} \EE[X] = \lim_{M \to \infty} \frac{1 - e^{-Mp} - Mpe^{-Mp}}{p} = \infty.\]
Also, note that if $p = \frac{c}{M}$, $c \in \mathbb{R_+}$ ($0 < e^{-c} + ce^{-c} < 1$),
\[\lim _{M \to \infty} \EE[X] = \lim_{M \to \infty} \frac{1 - e^{-c} - ce^{-c}}{p} = \infty.\]
\textbf{Proof. }
Fix $a \in \NN$ such that $a > 11$ and let $A = \{1, \ldots, \lfloor\frac{a}{p}\rfloor\}$. Since   $\frac{1}{M} \ll p$, we have that $\lfloor\frac{a}{p}\rfloor \leq M$ for large enough $M$. Consider the following events:
\begin{itemize}
    \item $E_1$: No generator selected is less than $\frac{1}{ap}$.  \par
    Let $X_1$ be the number of generators selected from $\{1,\ldots,\lfloor\frac{1}{ap}\rfloor\}$. Then 
    \[\Pr[\overline{E_1}] = \Pr[X_1 > 0] \leq \EE[X_1] \leq p \cdot \frac{1}{ap} = \frac{1}{a}.\]

    \item $E_2:$ At most $\frac{3a}{2}$ generators are selected from $A$.\par 
    Let $X_2$ be the number of generators selected in $A$, then $X_2$ is a binomial random variable with $n = \frac{a}{p}$ and we can use the bound (Feller \textcolor{blue}{I can add this to the appendix})

    \[\Pr[\overline{E_2}] = \Pr\left[X_2 > \frac{3a}{2}\right] \leq  \frac{\frac{3a}{2}(1 - p)}{(\frac{3a}{2} - a)^2} \leq \frac{6}{a}.\]

    Also, note that by the union bound \[\Pr[E_1\land E_2] \leq 1 - \frac{1}{a} - \frac{6}{a} = 1 - \frac{7}{a}.\]  

    \item $E_3:$ At least $\frac{a}{2}$ generators are selected from $A$. \par 
    Similarly, we can use the bound for the other tail of the distribution so that 
    \[\Pr[ \overline{E_3}] = \Pr\left[X_2 < \frac{a}{2}\right] \leq  \frac{(n - \frac{a}{2})p}{(np - \frac{a}{2})^2} = \frac{a - (\frac{a}{2})p}{(\frac{a}{2})^2} \leq \frac{4}{a}.\]
    
    \item $E_4:$ The generators selected from $A$ are minimal.\par 
    Let $Y_{(1)}, Y_{(2)}, \ldots, Y_{(k)}$ denote the first $k$ generators selected in $A$. Assume $E_1$ and $E_2$. We have that $E_1$ implies $Y_{(1)} \geq \frac{1}{ap}$ and $E_2$ implies $k \leq \frac{3a}{2}$. \par
    First we bound for the probability that, given $E_1$ and $E_2$, $b \in A$ is selected as a generator. By conditional probability 
    \begin{align*}
        \Pr[b \text{ is selected}] &= \Pr[b \text{ is selected}|E_1 \land E_2]\Pr[E_1 \land E_2]  \\
        &+  \Pr[b \text{ is selected}|\overline{E_1 \land E_2}]\Pr[\overline{E_1 \land E_2}],
    \end{align*}
    and so
    \[\Pr[b \text{ is selected}|E_1 \land E_2] \leq \frac{\Pr[b \text{ is selected}]}{\Pr[E_1 \land E_2]} \leq  \frac{p}{1 - \frac{7}{a}}.  \] 
    Now, note that $Y_{(2)}$ is not minimal if a multiple of $Y_{(1)}$ is selected in $A$. Thus, if we fix $Y_{(1)} = y_1 \geq \frac{1}{ap}$, $Y_{(1)}$ is not minimal if $b \in \{2y_1, 3y_1, \ldots, c_1y_1\}$ is selected, where $c_1y_1$ is the largest multiple of $y_1$ which does not exceed $\frac{a}{p}$. Since $y_1 \geq \frac{1}{ap}$, we have that $c_1 \leq a^2$. Then, using the union bound, 
    \[\Pr[Y_{(2)} \text{ is not minimal}|E_1\land E_2 \land Y_{(1)} = y_1] \leq \frac{pa^2}{1 - \frac{7}{a}} .\]
    If we sum over all possible $y_1$, we get that 
    \[\Pr[Y_{(2)} \text{ is not minimal}|E_1\land E_2] \leq \frac{pa^2}{1 - \frac{7}{a}} .\]
    Similarly, for $2 \leq t \leq k$ and fixed $Y_{(1)} = y_1, \ldots, Y_{(t - 1)} = y_{t - 1}$, $Y_{(t)}$ is not minimal if the first $t - 1$ numbers selected from $A$ can generate $Y_{(t)}$. For the possible numbers generated by the first $t$ numbers selected, there are at most $a^2$ choices for each coefficient, so there are at most $a^{2t}$ such linear combinations. Then 
    \[\Pr[Y_{(t)} \text{ is not minimal}|E_1\land E_2] \leq \frac{pa^{2t}}{1 - \frac{7}{a}} .\]
    Therefore, since $Y_{(1)}$ is always minimal, we can use the union bound and $k \leq \frac{3a}{2}$ to conclude that
    \[\Pr[E_4|E_1 \land E_2] \geq 1 - \frac{p}{1 - \frac{7}{a}}\sum_{t = 1}^{\frac{3a}{2} - 1}a^{2t} = 1 - o(1).\]
    Thus,  
    \[\Pr[E_4] = \Pr[E_4| E_1 \land E_2]\Pr[E_1\land E_2] \geq 1 - \frac{7}{a} - o(1).\] 
\end{itemize}


Finally, note that by union bound, 
\[\Pr[E_4 \land E_3] \geq 1 - \frac{11}{a} - o(1).\] 
Therefore, for every $N \in \NN$ and $\varepsilon > 0$, there exists $K$ such that $M \geq K$ implies \[\Pr[f(S) > N], \; \Pr[g(S) > N], \; \Pr[e(S) > N] > 1 - \varepsilon.\].


\section{Upper bound}\label{sec:results:upperbound}

I conjecture that the hypothesis that $q$ is prime can be relaxed.
\subsection{Iteraded sumsets in cyclic groups}
\begin{lemma}\label{lem:sumset}
    Let $q$ be a prime number and $S$ be a random subset of $\mathbb{Z}_q$ of size $4\lfloor3\log_2 q\rfloor$. As $q$ tends to infinity, $2\lfloor3\log_2 q\rfloor S$ covers $\mathbb{Z}_q$ almost always. 
\end{lemma}

Let $q$ be a prime number and let $s \in \mathbb{N}$ such that $s\leq q$. Let $S$ be a uniformly random subset of $\mathbb{Z}_q$ of size $s$, that is, 
\[\Pr(S) = \frac{1}{\binom{q}{s}}.\]
For a given $z \in \mathbb{Z}_q$ and $k \in \mathbb{N}$ for which $k \leq s/2$, let 
\[N_z^k := \left\{K \subseteq \mathbb{Z}_q: |K| = k, \sum_{t \in K} t = z\right\}.\]
Note that $|N_z^k| = \frac{1}{q}{\binom{q}{k}}$, since $K \in N_0^k$ if and only if $K + k^{-1}z \in N_z^k$ for every $z \in \mathbb{Z}_q$.\par
For $K \in N_z^k$, let $A_K$ be the event that $K \subset S$. Let $X_K$ be the indicator variable of $A_K$.
We define the random variable 
\[X_z = \sum_{K \in N_z^k} X_K.\]
Note that $X_z$ counts the number of sets of size $k$ which add up to $z$. We provide two ways of finding $\EE[X_z]$. The first one uses that, for any $K \subset N^k_z$, 
\[\EE[X_K] = \Pr[A_K] = \frac{\binom{q - k}{s - k}}{\binom{q}{s}},\]
and so we get that
\begin{align*}
    \EE[X_z] = \sum_{K \in N_z^k} \EE[X_K] = |N_z^k|\EE[X_K] = \frac{1}{q}{\binom{q}{k}}\frac{\binom{q - k}{s - k}}{\binom{q}{s}} = \frac{1}{q} {\binom{s}{k}}.
\end{align*}
\par
This motivates the second way, for we know that 
\[\sum_{z \in Z_q} X_z = {\binom{s}{k}},\]
and so
\[\binom{s}{k} = E\left[\sum_{z \in Z_q} X_z\right] =  \sum_{z \in Z_q} E[X_z].\]\par
As in the argument for finding $|N_z^k|$, for every $z \in \mathbb{Z}_q$, 
\[\EE[X_0] = \sum_{K \in N_0^k}\EE[X_K] = \sum_{K \in N_0^k} \EE[X_{K + k^{-1}z}] = \sum_{K \in N_z^k} \EE[X_K] = \EE[X_z].\]
Therefore, we also find that
\begin{equation}\label{eq:upperbound:expected}
E[X_z] = \frac{1}{q} {\binom{s}{k}}.
\end{equation}
Now, for $K, L \in N_z^k$, let $j \in \mathbb{N}$ and define
\[\Delta_j := \sum_{|K \cap L| = j} \Pr[A_K \land A_L].\]
\par Fix $j \leq k$, then 
\[\Pr[A_K \land A_L] = \frac{\binom{q - 2k + j}{s - 2k + j}}{\binom{q}{s}}.\]
\par
We can bound the number of events for which $|K \cap L| = j$. First we choose $K$ as any set in $N_z^k$ and then we choose the remaining $k- j$ elements as any subset of $\mathbb{Z}_q \setminus K$ with size $k - j$. Thus, 
\[\Delta_j \leq \frac{\binom{p}{k} \binom{q - k}{k - j}\binom{q - 2k + j}{s - 2k + j}}{q\binom{q}{s}}.\]
\par This implies that, using \ref{eq:upperbound:expected},
\begin{align*}
    \frac{\Delta_j}{\EE[X_z]^2} &\leq \frac{\binom{q}{k} \binom{q - k}{k - j}\binom{q - 2k + j}{s - 2k + j}}{\frac{1}{q} \binom{s}{k}\frac{1}{q} \binom{s}{k}q\binom{q}{s}} \\
    &= \frac{\frac{q!}{(q - k)!k!}\frac{(p - k)!}{(k - j)!(q - 2k + k)!}\frac{(q - 2k + j)!}{(s - 2k + j)!(q - s)!}}{\frac{1}{q}\binom{s}{k}\frac{s!}{(s - k)!k!}\frac{q!}{(q - s)!s!}} \\
    &= \frac{q\binom{s - k}{k - j}}{\binom{s}{k}}.
\end{align*}
Let $s = 4\lfloor 3 \log_2 q \rfloor$ and $k = 2\lfloor 3 \log_2 q \rfloor$. Using that $\binom{s - k}{t}$ is maximized at $t = \lfloor (s - k) / 2\rfloor$,
\begin{align*}
\frac{\Delta_j}{\EE[X_z]^2} \leq \frac{q \binom{2\lfloor 3 \log_2 q\rfloor}{\lfloor 3 \log_2 q \rfloor}}{\binom{4\lfloor 3\log_2 q \rfloor}{2\lfloor 3\log_2 q \rfloor}} \leq \frac{q}{\binom{2\lfloor 3 \log_2 q \rfloor }{ \lfloor 3 \log_2 q \rfloor}} \leq \frac{q}{2^{\lfloor 3 \log_2 q \rfloor}} \sim \frac{1}{q^2},
\end{align*}
since \(\binom{2\lfloor q^{\alpha} \rfloor}{\lfloor 3 \log_2 q \rfloor}^2 \leq \binom{4\lfloor 3 \log_2 q \rfloor }{2\lfloor 3 \log_2 q \rfloor}\) (I can prove this in a lemma or in the appendix).   \par
This proves that
\[\Pr[X_z = 0] \leq \frac{\Delta}{\EE[X_z]^2} = \sum_{j = 0}^k \frac{\Delta_j}{\EE[X_z]^2} \leq \frac{(k + 1)}{q^2}.\]
Therefore, by the union bound,
\[\Pr[\bigvee_{z \in \mathbb{Z}_q} X_z = 0] \leq \frac{(k + 1)}{q}.\]

\subsection{Proof of the upper bound} 
\begin{theorem}\label{thm:upperbound}
    Let $g(x)$ be a function for which $x(\log x)^2 \in o(g(x))$ .Then
    \[\lim_{p \to 0}\Pr\left[F(S) \leq g\left(\frac{1}{p}\right)\right] = 1.\] 
\end{theorem}

\par The proof of this Theorem consists of several parts. The strategy is to prove that the Ápery set of a subsemigroup of $S$ is completed before step $g\left(\frac{1}{p}\right)$ with high probability, since $F(S)$ is less than the maximum element of this Ápery set. The proof has the following structure: 
\begin{enumerate}
\item First, we will find a step for which a prime $q$ is chosen with high probability (E1). 
\item Then, in the spirit of the \textcolor{blue}{Lemma}, we will find a step such that $s$ elements, which are different modulo $q$, are chosen with high probability (E2). 
\item Finally, we will apply the \textcolor{blue}{Lemma} to the Ápery set of a subsemigroup of $S$ generated by the subset in part 2. 
\end{enumerate}
\textit{Proof. }
\subsubsection*{Part 1}
Let \(h(x)\) be a function such that \(h(x) \in o(x (\log x)^2)\) and \(x\log x \in o(h(x))\). Let $t(x) = 20x \log x$. Consider the event
$E_1$ that there exists a prime $q \in S$, such that 
\[t\left(\frac{1}{p}\right) \leq q \leq h\left(\frac{1}{p}\right).\]
\par 
Let $q_n$ be the $n$-th prime number and let $k_x$ be the number of primes between $20x\log x$ and $h(x)$. For $n \geq 6$, by the \textcolor{blue}{Prime Number Theorem}, 
\[n(\log n + \log \log n - 1) < q_n < n(\log n + \log\log n) = o(h(n)).\]

\par Thus, $n = o(k_n)$ (\textcolor{blue}{I can prove this if it is not clear}) and, for every $c > 0$,  
\[\lim_{p \to 0}\Pr[\lnot E_1] \geq \lim_{p \to 0} (1 - p)^{k_{\frac{1}{p}}} \geq \lim_{p \to 0} (1 - p)^{\frac{c}{p}} = e^{-c}.\]
Therefore, 
\[\lim_{p \to 0}\Pr[E_1] = 1.\]
\subsubsection*{Part 2}

Now, assume $E_1$. Then $S$ contains a prime number $q$ for which 
\[t\left(\frac{1}{p}\right) \leq q \leq h\left(\frac{1}{p}\right).\]
\par Let $s = 4\lfloor3\log_2 q \rfloor$, as in the \textcolor{blue}{Lemma}. 
\par Let $A := \{q + 1, q + 2, \ldots,  2q\}$. Consider the event \textbf{E2} that at least $s$ generators are selected in $A$. Let $X_1$ be the number of generators selected in $A$, then $X_1$ is a binomial random variable with parameters $n = q$ and $p$. Then, in a similar way to $E2$ in \textcolor{blue}{Theorem 1}, we use the \textcolor{blue}{Binomial Distribution Tail Bound} to show that, assuming that $p$ is small enough so that $qp > s$ for all possible $q$,
\begin{align*}
    \Pr[ \overline{E_2}  | E_1] = \Pr\left[X_1 < s\right] \leq \Pr\left[X_2 < s\right] \leq \frac{(n - s)p}{(np - s)^2} = \frac{(q - s)p}{(qp - s)^2}.
\end{align*}
\par Thus, bounding by the worst case asymptotically, (\textcolor{blue}{needs to be explained better})
\[\lim_{p \to 0} P[\overline{E_2} | E_1] =  \lim_{p \to 0}\frac{\left(h\left(\frac{1}{p}\right) - 4\left\lfloor3\log_2 h\left(\frac{1}{p}\right) \right\rfloor\right)p}{\left(20 \log \frac{1}{p} - 4\lfloor3\log_2 t\left(\frac{1}{p}\right) \rfloor\right)^2} = 0.\]
\par We conclude that
\[\lim_{p \to 0} \Pr[E_2 | E_1] = 1,\]
and so
\[\lim_{p \to 0} \Pr[E_1 \land E_2] = \lim_{p \to 0} \Pr[E_2  | E_1]\Pr[E_1] = 1.\]


\subsubsection*{Part 3}

\par Finally, assume $E_1$ and $E_2$. Let $B = \{Y_{1}, \ldots, Y_{s}\}$ be a randomly selected subset of size $s$ of the generators selected in $E_2$.  Since the generators are chosen randomly and $|A| = q$, we can apply the \textcolor{blue}{Lemma} to the Ápery set of the subsemigroup generated by $B$, denoted by $G(B)$, and conclude that the Ápery set of $G(B)$ will be completed before step $h\left(\frac{1}{p}\right)2\left\lfloor 3\log_2 h\left(\frac{1}{p}\right)\right\rfloor$ with high probability as $p \to 0$. 
\par Thus, if $g(x)$ be a function for which $x(\log x)^2 \in o(g(x))$ (\textcolor{blue}{Probably needs to be explained better}),
\[\lim_{p \to  0} \Pr\left[F(G(B)) \leq g\left(\frac{1}{p}\right)\right] = 1.\]
Since $F(S) \leq F(G(B))$, we conclude that
\[\lim_{p \to 0}\Pr\left[F(S) \leq g\left(\frac{1}{p}\right)\right] = 1. \qed \] 


\section{Conclusion}
